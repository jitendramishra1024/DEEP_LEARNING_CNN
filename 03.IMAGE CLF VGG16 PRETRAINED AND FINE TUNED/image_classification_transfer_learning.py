# -*- coding: utf-8 -*-
"""IMAGE_CLASSIFICATION_TRANSFER_LEARNING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1diOvH4C4M2FIJbo5uQjtpL7BDiBwVK0Q
"""

#APPROACH USED 
#################################
#BASIC CNN WITH DATA CONSTRAINT 
#################################
#EARLIER CASE WE USED 
                     #TRAINING SET (8000 IMAGE ) 4000 CAT 4000 DOG IMAGE 
                     #TEST SET     (2000 IMAGE) 1000 CAT  1000 DOG IMAGE 
#IN THIS APPROACH WE WILL USE 
                    #TRAINING SET (3000 IMAGE ) 1500 CAT 1500 DOG IMAGE 
                    #TEST SET     (1000 IMAGE) 500 CAT  500 DOG IMAGE

#3 APPROACHES WE WILL FOLLOW 
                    #TRANSFER LEARNING 
                    #VGG16 PRETRAINED 
                    #VGG16 FINETUNING

#####################################################################
#FIRST APPROACH 
 #VGG16 Pre-trained CNN model as a Feature Extractor with out data augmentation ****************
 #TRAINING ACCURACY :1.00
 #VALIDATION ACCURACY:0.89  
 #CONCLUSION: OVERFITTED 
#####################################################################

#Mount Google drive
from google.colab import drive 
drive.mount('/content/drive')

from zipfile import ZipFile
file_name = "/content/drive/My Drive/Colab Notebooks/dataset_cat_dog.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print("unzipping completed")

# Commented out IPython magic to ensure Python compatibility.
import glob
import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img

# %matplotlib inline

IMG_DIM = (150, 150)
#As we want         #TRAINING SET (3000 IMAGE ) 1500 CAT 1500 DOG IMAGE 
                    #TEST SET     (1000 IMAGE) 500 CAT  500 DOG IMAGE

cat_train_files = glob.glob('/content/dataset/training_set/cats/*')
dog_train_files = glob.glob('/content/dataset/training_set/dogs/*')
train_files=cat_train_files[:1500]+dog_train_files[:1500]
train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]
train_imgs = np.array(train_imgs)
train_labels = [fn.split('/')[-1].split('.')[0].strip() for fn in train_files]

cat_validation_files = glob.glob('/content/dataset/test_set/cats/*')
dog_validation_files = glob.glob('/content/dataset/test_set/dogs/*')
validation_files=cat_validation_files[:500]+dog_validation_files[:500]
validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]
validation_imgs = np.array(validation_imgs)
validation_labels = [fn.split('/')[-1].split('.')[0].strip() for fn in validation_files]

print('Train dataset shape:', train_imgs.shape, 
      '\tValidation dataset shape:', validation_imgs.shape)

#SCALE THE IMAGE AFTER CONVERTING INTO FLLOAT
train_imgs_scaled = train_imgs.astype('float32')
validation_imgs_scaled  = validation_imgs.astype('float32')
train_imgs_scaled /= 255
validation_imgs_scaled /= 255

#ENCODE LABEL :
# encode text category labels
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(train_labels)
train_labels_enc = le.transform(train_labels)
validation_labels_enc = le.transform(validation_labels)

batch_size = 30
num_classes = 2
epochs = 30
input_shape = (150, 150, 3)

#VGG MODEL

from keras.applications import vgg16
from keras.models import Model
import keras

vgg = vgg16.VGG16(include_top=False, weights='imagenet', 
                                     input_shape=input_shape)

output = vgg.layers[-1].output
output = keras.layers.Flatten()(output)

vgg_model = Model(vgg.input, output)
vgg_model.trainable = False

for layer in vgg_model.layers:
    layer.trainable = False

vgg_model.summary()

import pandas as pd
pd.set_option('max_colwidth', -1)

layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]
pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])

#PLEASE NOTE THAT WE HAVE TAKEN ONLY 2+2+3+3+3=13 layers only and weights we are not updating so all layers are false and rest 3 dense layer for classification will be created by us 

# It is quite clear from the preceding output that all the layers of the VGG-16 model are frozen, which is good]
# , because we don’t want their weights to change during model training. The last activation feature map in the
#  VGG-16 model (output from block5_pool) gives us the bottleneck features, which can then be flattened and fed
#   to a fully connected deep neural network classifier

# We flatten the bottleneck features in the vgg_model object to make them ready to be fed to our fully connected 
# classifier. A way to save time in model training is to use this model and extract out all the features from our
#  training and validation datasets and then feed them as inputs to our classifier. Let’s extract out the bottleneck 
#  features from our training and validation sets now.

def get_bottleneck_features(model, input_imgs):
    
    features = model.predict(input_imgs, verbose=0)
    return features

train_features_vgg = get_bottleneck_features(vgg_model, train_imgs_scaled)
validation_features_vgg = get_bottleneck_features(vgg_model, validation_imgs_scaled)

print('Train Bottleneck Features:', train_features_vgg.shape, 
      '\tValidation Bottleneck Features:', validation_features_vgg.shape)

#create dense layer for clasification 
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer
from keras.models import Sequential
from keras import optimizers

input_shape = vgg_model.output_shape[1]

model = Sequential()
model.add(InputLayer(input_shape=(input_shape,)))
model.add(Dense(512, activation='relu', input_dim=input_shape))
model.add(Dropout(0.3))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(lr=1e-4),
              metrics=['accuracy'])

model.summary()

history = model.fit(x=train_features_vgg, y=train_labels_enc,
                    validation_data=(validation_features_vgg, validation_labels_enc),
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1)

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc)+1)

plt.plot(epochs, acc, 'g', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Train Accuracy: %.3f, Val Accuracy: %.3f' % (acc[-1], val_acc[-1]), fontsize=12)
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'g', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Train Loss: %.3f, Val Loss: %.3f' % (loss[-1], val_loss[-1]), fontsize=12)
plt.legend()

plt.show()

#####################################################################
#SECOND  APPROACH 
 #VGG16 Pre-trained CNN model as a Feature Extractor with data augmentation ****************
 #TRAINING ACCURACY :0.88
 #VALIDATION ACCURACY:0.99  
 #CONCLUSION: MODEL UNDER FITTED
#####################################################################

train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,
                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, 
                                   horizontal_flip=True, fill_mode='nearest')

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)
val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer
from keras.models import Sequential
from keras import optimizers

model = Sequential()
model.add(vgg_model)
model.add(Dense(512, activation='relu', input_dim=input_shape))
model.add(Dropout(0.3))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(lr=2e-5),
              metrics=['accuracy'])

model.summary()

history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=val_generator, validation_steps=50, verbose=1)

model.save('/content/drive/My Drive/Colab Notebooks/cats_dogs_tlearn_vgg_16_pretrained_img_aug_cnn.h5')

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc)+1)

plt.plot(epochs, acc, 'g', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Train Accuracy: %.3f, Val Accuracy: %.3f' % (acc[-1], val_acc[-1]), fontsize=12)
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'g', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Train Loss: %.3f, Val Loss: %.3f' % (loss[-1], val_loss[-1]), fontsize=12)
plt.legend()

plt.show()

#####################################################################
#THIRD  APPROACH 
 #VGG16 Pre-trained CNN model with Fine-tuning and Image Augmentation
 #TRAINING ACCURACY :0.99
 #VALIDATION ACCURACY:0.95 
 #CONCLUSION: MODEL IS PERFECT
#####################################################################

#We will now leverage our VGG-16 model object stored in the vgg_model variable and unfreeze convolution blocks 4 and 5 while keeping the first three blocks frozen

vgg_model.trainable = True

set_trainable = False
for layer in vgg_model.layers:
    if layer.name in ['block5_conv1', 'block4_conv1']:
        set_trainable = True
    if set_trainable:
        layer.trainable = True
    else:
        layer.trainable = False
        
print("Trainable layers:", vgg_model.trainable_weights)

layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]
pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])

#DATA AUGMENTATION 

train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,
                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, 
                                   horizontal_flip=True, fill_mode='nearest')

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)
val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer
from keras.models import Sequential
from keras import optimizers

model = Sequential()
model.add(vgg_model)
model.add(Dense(512, activation='relu', input_dim=input_shape))
model.add(Dropout(0.3))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(lr=1e-5),
              metrics=['accuracy'])

model.summary()

history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=val_generator, validation_steps=50, verbose=1)

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc)+1)

plt.plot(epochs, acc, 'g', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Train Accuracy: %.3f, Val Accuracy: %.3f' % (acc[-1], val_acc[-1]), fontsize=12)
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'g', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Train Loss: %.3f, Val Loss: %.3f' % (loss[-1], val_loss[-1]), fontsize=12)
plt.legend()

plt.show()

model.save('/content/drive/My Drive/Colab Notebooks/cats_dogs_tlearn_vgg_16_finetuned_img_aug_cnn.h5')

